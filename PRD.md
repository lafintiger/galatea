# Galatea - Local Voice AI Companion

## Product Requirements Document (PRD)
**Version:** 1.0  
**Date:** December 6, 2024  
**Codename:** Galatea (Gala)

---

## 1. Vision & Overview

### 1.1 Product Vision
Galatea is a local, privacy-first AI voice companion that enables seamless, natural conversation with locally-running language models. Named after the mythological figure brought to life by Pygmalion, Galatea represents the aspiration to create a truly lifelike AI companion that grows and evolves with its user.

### 1.2 Core Philosophy
- **Privacy First**: All processing happens locallyâ€”no data leaves the user's machine
- **Seamless Interaction**: Voice-first experience that feels natural and fluid
- **Extensible Foundation**: Modular architecture designed for continuous capability expansion
- **User Empowerment**: Users control their AI's personality, voice, memory, and capabilities

### 1.3 Target Platform
- Primary: Windows PC (RTX 5090 24GB VRAM, 64GB RAM)
- Secondary: macOS (future)
- Deployment: Local-first, with potential for LAN access later

---

## 2. Technical Architecture

### 2.1 System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GALATEA WEB UI (React + TypeScript)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Voice Interface â”‚  â”‚   Controls   â”‚  â”‚   Work Area (Phase 3+)   â”‚  â”‚
â”‚  â”‚  - Visualizer    â”‚  â”‚   - Settings â”‚  â”‚   - Documents            â”‚  â”‚
â”‚  â”‚  - Status        â”‚  â”‚   - Model    â”‚  â”‚   - Images               â”‚  â”‚
â”‚  â”‚  - Transcript    â”‚  â”‚   - Voice    â”‚  â”‚   - Code                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ WebSocket (bidirectional audio + events)
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GALATEA CORE (Python + FastAPI)                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   Conversation Orchestrator                     â”‚    â”‚
â”‚  â”‚  - Context Management    - Memory Injection    - Persona        â”‚    â”‚
â”‚  â”‚  - Time Awareness        - Tool Dispatch       - Multi-turn     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STT Service â”‚ â”‚ LLM Service â”‚ â”‚ TTS Service â”‚ â”‚ Memory Service  â”‚   â”‚
â”‚  â”‚ (Whisper)   â”‚ â”‚ (Ollama)    â”‚ â”‚ (Piper)     â”‚ â”‚ (ChromaDB+SQL)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚               â”‚               â”‚                  â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      Tool Registry (Extensible)                   â”‚  â”‚
â”‚  â”‚  Phase 1: Core    Phase 3: Search    Phase 4: Vision, Image Gen  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Wyoming       â”‚    â”‚    Ollama     â”‚    â”‚ Wyoming       â”‚
â”‚ Whisper       â”‚    â”‚  localhost    â”‚    â”‚ Piper         â”‚
â”‚ :10300        â”‚    â”‚  :11434       â”‚    â”‚ :10200        â”‚
â”‚ (Docker)      â”‚    â”‚               â”‚    â”‚ (Docker)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚         Future Integrations             â”‚
                            â”‚  - Perplexica (:3000) / SearXNG (:4000) â”‚
                            â”‚  - Stable Diffusion / ComfyUI           â”‚
                            â”‚  - Code Execution Sandbox               â”‚
                            â”‚  - Camera / Vision Models               â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Technology Stack

| Layer | Technology | Rationale |
|-------|------------|-----------|
| **Frontend** | React 18 + TypeScript + Vite | Component architecture, type safety, fast HMR |
| **Styling** | Tailwind CSS + CSS Variables | Rapid styling, easy theming |
| **Audio** | Web Audio API + MediaRecorder | Native browser audio handling |
| **State** | Zustand | Lightweight, flexible state management |
| **Backend** | Python 3.11 + FastAPI | Async, ML ecosystem, WebSocket support |
| **Real-time** | WebSockets | Bidirectional audio streaming |
| **Database** | SQLite â†’ PostgreSQL | Conversations, settings, user data |
| **Vector Store** | ChromaDB | Local embeddings for RAG |
| **LLM** | Ollama | Local model serving |
| **STT** | Faster-Whisper (Wyoming) | Fast, accurate transcription |
| **TTS** | Piper (Wyoming) | Natural speech synthesis |

### 2.3 Service Endpoints

| Service | Protocol | Host | Port |
|---------|----------|------|------|
| Galatea Backend | HTTP/WS | localhost | 8000 |
| Galatea Frontend | HTTP | localhost | 5173 |
| Ollama | HTTP | localhost | 11434 |
| Whisper (STT) | Wyoming | localhost | 10300 |
| Piper (TTS) | Wyoming | localhost | 10200 |
| Perplexica | HTTP | localhost | 3000 |
| SearXNG | HTTP | localhost | 4000 |

---

## 3. Feature Specification

### 3.1 Phase 1: Walking (MVP) ğŸš¶
**Goal:** Establish the core voice conversation loop

#### 3.1.1 Voice Input
- [x] Push-to-talk button (hold to record)
- [x] Visual feedback during recording (waveform/visualizer)
- [x] Audio capture via MediaRecorder API
- [x] Stream audio to backend via WebSocket
- [x] Real-time transcription display

#### 3.1.2 LLM Integration
- [x] Connect to Ollama API
- [x] Model selection dropdown (persisted preference)
- [x] Default model: `huihui_ai/qwen3-abliterated:8b`
- [x] System prompt with Galatea persona
- [x] Streaming response support

#### 3.1.3 Voice Output
- [x] Text-to-speech via Piper (Wyoming protocol)
- [x] Audio playback in browser
- [x] Manual interrupt button (stop speaking)
- [x] Female voice (configurable)

#### 3.1.4 Basic UI
- [x] Futuristic dark theme
- [x] Central voice interaction area
- [x] Audio visualizer (input + output)
- [x] Status indicators (listening, thinking, speaking)
- [x] Settings panel (model, voice, assistant name)

#### 3.1.5 Settings (Phase 1)
- [x] Assistant name (default: Galatea, nickname: Gala)
- [x] LLM model selection
- [x] Voice selection (female EN-US and EN-GB voices)
- [x] Response style toggle (concise/conversational)

### 3.2 Phase 2: Running ğŸƒ
**Goal:** Add intelligence and memory

#### 3.2.1 Voice Activation
- [ ] Voice Activity Detection (VAD)
- [ ] Configurable silence threshold
- [ ] Visual indicator when VAD active

#### 3.2.2 Memory System
- [ ] Conversation history persistence (SQLite)
- [ ] Session management (new/continue conversation)
- [ ] ChromaDB integration for semantic memory
- [ ] RAG: Inject relevant memories into context
- [ ] User profile storage (facts about user)

#### 3.2.3 Enhanced UI
- [ ] Transcript panel (toggleable)
- [ ] Conversation history browser
- [ ] Memory viewer/editor

### 3.3 Phase 3: Flying âœˆï¸
**Goal:** Contextual awareness and content handling

#### 3.3.1 Time Awareness
- [ ] Current time/date injection
- [ ] Time since last conversation
- [ ] Holiday awareness
- [ ] Contextual greetings (morning/evening)

#### 3.3.2 Wake Word
- [ ] Local wake word detection
- [ ] Configurable wake phrase
- [ ] Always-listening mode (optional)

#### 3.3.3 Work Area
- [ ] Document upload/display
- [ ] Text extraction from documents
- [ ] URL content fetching
- [ ] Context injection from work area

#### 3.3.4 Multi-language
- [ ] Language detection
- [ ] Multi-language TTS voices
- [ ] Translation capabilities

### 3.4 Phase 4: Soaring ğŸš€
**Goal:** Advanced capabilities and tool use

#### 3.4.1 Tool System
- [ ] Extensible tool registry
- [ ] Web search (Perplexica/SearXNG integration)
- [ ] Code execution sandbox
- [ ] File operations

#### 3.4.2 Image Generation
- [ ] Stable Diffusion / ComfyUI integration
- [ ] Voice-triggered image generation
- [ ] Image display in work area

#### 3.4.3 Vision Capabilities
- [ ] Vision model for work area (`qwen3-vl:8b`)
- [ ] Camera access for user observation
- [ ] Emotion detection
- [ ] Multi-model coordination

#### 3.4.4 Advanced UI
- [ ] Theme system (multiple visual styles)
- [ ] Avatar/visual representation
- [ ] Customizable layouts

---

## 4. Data Models

### 4.1 User Settings
```typescript
interface UserSettings {
  id: string;
  assistantName: string;           // default: "Galatea"
  assistantNickname: string;       // default: "Gala"
  selectedModel: string;           // Ollama model ID
  selectedVoice: string;           // Piper voice ID
  responseStyle: 'concise' | 'conversational';
  activationMode: 'push-to-talk' | 'vad' | 'wake-word';
  wakeWord?: string;
  transcriptVisible: boolean;
  theme: string;
  language: string;
}
```

### 4.2 Conversation
```typescript
interface Conversation {
  id: string;
  title: string;
  createdAt: DateTime;
  updatedAt: DateTime;
  messages: Message[];
  summary?: string;              // For memory/RAG
}

interface Message {
  id: string;
  conversationId: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  audioUrl?: string;            // Stored audio file
  timestamp: DateTime;
  metadata?: {
    model?: string;
    voice?: string;
    processingTime?: number;
  };
}
```

### 4.3 Memory Entry (RAG)
```typescript
interface MemoryEntry {
  id: string;
  content: string;
  embedding: number[];          // Vector for similarity search
  type: 'fact' | 'preference' | 'event' | 'conversation';
  source: string;               // conversation ID or manual
  createdAt: DateTime;
  lastAccessed?: DateTime;
  importance: number;           // For memory prioritization
}
```

---

## 5. API Specification

### 5.1 WebSocket Events

#### Client â†’ Server
```typescript
// Start recording
{ type: 'audio_start' }

// Audio chunk (base64 encoded)
{ type: 'audio_chunk', data: string }

// Stop recording
{ type: 'audio_stop' }

// Interrupt AI speech
{ type: 'interrupt' }

// Text input (alternative to voice)
{ type: 'text_message', content: string }
```

#### Server â†’ Client
```typescript
// Transcription result
{ type: 'transcription', text: string, final: boolean }

// LLM response chunk (streaming)
{ type: 'llm_chunk', text: string }

// LLM response complete
{ type: 'llm_complete', fullText: string }

// Audio chunk for playback
{ type: 'audio_chunk', data: string, format: 'wav' }

// Audio playback complete
{ type: 'audio_complete' }

// Status updates
{ type: 'status', state: 'listening' | 'processing' | 'speaking' | 'idle' }

// Error
{ type: 'error', message: string, code: string }
```

### 5.2 REST Endpoints

```
GET  /api/settings              - Get user settings
PUT  /api/settings              - Update user settings
GET  /api/models                - List available Ollama models
GET  /api/voices                - List available Piper voices
GET  /api/conversations         - List conversations
GET  /api/conversations/:id     - Get conversation with messages
POST /api/conversations         - Create new conversation
DELETE /api/conversations/:id   - Delete conversation
GET  /api/health                - Health check
```

---

## 6. Piper Voice Configuration

### 6.1 Required Voices (Female, English)
Download and configure the following Piper voices:

#### US English (en_US)
| Voice | Quality | Style |
|-------|---------|-------|
| en_US-amy-medium | Medium | Neutral |
| en_US-amy-low | Low | Neutral |
| en_US-lessac-medium | Medium | Expressive |
| en_US-lessac-high | High | Expressive |
| en_US-libritts-high | High | Various |
| en_US-ljspeech-medium | Medium | Audiobook |
| en_US-ljspeech-high | High | Audiobook |

#### British English (en_GB)
| Voice | Quality | Style |
|-------|---------|-------|
| en_GB-alba-medium | Medium | Scottish |
| en_GB-jenny_dioco-medium | Medium | Southern British |
| en_GB-cori-medium | Medium | Welsh |

### 6.2 Default Voice
`en_US-lessac-medium` - Good balance of quality and naturalness

---

## 7. Ollama Model Configuration

### 7.1 Recommended Models

| Purpose | Model | Size | Notes |
|---------|-------|------|-------|
| **Default Chat** | `huihui_ai/qwen3-abliterated:8b` | 5GB | Fast, natural conversation |
| **High Quality** | `huihui_ai/qwen3-abliterated:32b` | 19GB | Slower but more capable |
| **Vision** | `qwen3-vl:8b` | 6.1GB | For work area / documents |
| **Embeddings** | `bge-m3:latest` | 1.2GB | For RAG memory system |

### 7.2 System Prompt Template
```
You are {assistant_name}, a thoughtful and engaging AI companion. Your nickname is {nickname}.

Personality traits:
- Warm and genuine in conversation
- Intellectually curious
- Supportive and encouraging
- Occasionally playful with a subtle wit

Response style: {response_style}
- If "concise": Keep responses brief and to the point. 1-3 sentences unless more detail is requested.
- If "conversational": Be more expansive and natural. Share thoughts, ask follow-up questions, engage deeply.

Context:
- Current time: {current_time}
- User name: {user_name}
- Relevant memories: {memories}

Remember: You are having a voice conversation. Keep responses natural for speech - avoid bullet points, 
code blocks (unless specifically discussing code), and overly structured formatting.
```

---

## 8. Project Structure

```
galatea/
â”œâ”€â”€ frontend/                    # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceInterface/  # Main voice interaction
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioVisualizer/ # Waveform display
â”‚   â”‚   â”‚   â”œâ”€â”€ Settings/        # Settings panel
â”‚   â”‚   â”‚   â”œâ”€â”€ Transcript/      # Chat transcript
â”‚   â”‚   â”‚   â””â”€â”€ WorkArea/        # Document/content area (Phase 3)
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useAudioRecorder.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts
â”‚   â”‚   â”‚   â””â”€â”€ useAudioPlayer.ts
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â”œâ”€â”€ settingsStore.ts
â”‚   â”‚   â”‚   â””â”€â”€ conversationStore.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â””â”€â”€ themes/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ backend/                     # Python FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket.py     # WebSocket handler
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py      # Settings endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py        # Model listing
â”‚   â”‚   â”‚   â””â”€â”€ conversations.py # Conversation CRUD
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ stt.py           # Whisper/Wyoming client
â”‚   â”‚   â”‚   â”œâ”€â”€ tts.py           # Piper/Wyoming client
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py           # Ollama client
â”‚   â”‚   â”‚   â”œâ”€â”€ memory.py        # Memory/RAG service
â”‚   â”‚   â”‚   â””â”€â”€ orchestrator.py  # Conversation flow
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py      # Pydantic models
â”‚   â”‚   â”‚   â””â”€â”€ conversation.py
â”‚   â”‚   â””â”€â”€ database/
â”‚   â”‚       â”œâ”€â”€ db.py            # Database connection
â”‚   â”‚       â””â”€â”€ migrations/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ docker/                      # Docker configurations
â”‚   â””â”€â”€ docker-compose.yml       # For additional services
â”‚
â”œâ”€â”€ data/                        # Local data storage
â”‚   â”œâ”€â”€ galatea.db               # SQLite database
â”‚   â”œâ”€â”€ chroma/                  # ChromaDB vector store
â”‚   â””â”€â”€ audio/                   # Stored audio files
â”‚
â”œâ”€â”€ PRD.md                       # This document
â”œâ”€â”€ README.md                    # Setup instructions
â””â”€â”€ .env.example                 # Environment template
```

---

## 9. Development Phases & Milestones

### Phase 1: Walking (MVP) - Week 1-2
**Milestone:** Complete voice conversation loop

- [ ] Project scaffolding (frontend + backend)
- [ ] Wyoming protocol client (STT + TTS)
- [ ] Ollama integration with streaming
- [ ] WebSocket communication
- [ ] Basic UI with visualizer
- [ ] Settings persistence
- [ ] Push-to-talk recording
- [ ] Audio playback
- [ ] Manual interrupt

**Success Criteria:** User can have a continuous voice conversation with Galatea

### Phase 2: Running - Week 3-4
**Milestone:** Memory and natural interaction

- [ ] VAD implementation
- [ ] SQLite conversation storage
- [ ] ChromaDB setup
- [ ] RAG memory injection
- [ ] Transcript UI
- [ ] Conversation history

**Success Criteria:** Galatea remembers past conversations and user preferences

### Phase 3: Flying - Week 5-6
**Milestone:** Contextual awareness

- [ ] Time awareness system
- [ ] Wake word detection
- [ ] Work area UI
- [ ] Document handling
- [ ] Multi-language support

**Success Criteria:** Galatea is contextually aware and can handle documents

### Phase 4: Soaring - Week 7+
**Milestone:** Advanced capabilities

- [ ] Tool system framework
- [ ] Web search integration
- [ ] Image generation
- [ ] Vision capabilities
- [ ] Theme system

**Success Criteria:** Galatea can use tools and see content

---

## 10. Success Metrics

### Core Experience
- **Latency:** Voice input to speech start < 2 seconds
- **Accuracy:** Transcription WER < 10%
- **Naturalness:** TTS sounds natural and appropriate
- **Reliability:** 99% success rate for conversation turns

### Engagement
- **Session Length:** Average conversation > 5 minutes
- **Return Rate:** User returns within 24 hours
- **Feature Usage:** Memory recalled in 30%+ of conversations

---

## 11. Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Wyoming protocol complexity | High | Build abstraction layer, fallback to HTTP |
| Audio latency | High | Stream in chunks, optimize buffer sizes |
| Memory context overflow | Medium | Implement summarization, relevance filtering |
| Model response quality | Medium | Careful prompt engineering, model selection |
| Cross-platform audio | Medium | Use Web Audio API standards, test early |

---

## 12. Future Considerations

### Potential Integrations
- **Home Assistant:** Use existing Wyoming infrastructure
- **Mobile App:** React Native companion app
- **Browser Extension:** Quick access to Galatea
- **API Mode:** Let other apps use Galatea as a service

### Advanced Features
- **Proactive Mode:** Galatea initiates conversation based on context
- **Learning Mode:** Fine-tune responses based on user feedback
- **Multi-user:** Support for multiple user profiles
- **Offline Mode:** Fully offline operation with local models

---

## Appendix A: Wyoming Protocol Reference

The Wyoming protocol is a simple TCP-based protocol for voice services.

### Connection
```python
# Connect to service
reader, writer = await asyncio.open_connection(host, port)
```

### Message Format
```python
# Send message
message = json.dumps({"type": "transcribe", "data": {...}})
writer.write(f"{len(message)}\n{message}".encode())

# Receive message
length = int(await reader.readline())
data = await reader.read(length)
message = json.loads(data)
```

### STT (Whisper) Events
- `transcribe` - Send audio for transcription
- `transcript` - Receive transcription result

### TTS (Piper) Events
- `synthesize` - Send text for synthesis
- `audio-start` - Audio stream starting
- `audio-chunk` - Audio data chunk
- `audio-stop` - Audio stream complete

---

## Appendix B: Environment Variables

```bash
# Backend
OLLAMA_HOST=http://localhost:11434
WHISPER_HOST=localhost
WHISPER_PORT=10300
PIPER_HOST=localhost
PIPER_PORT=10200
DATABASE_URL=sqlite:///./data/galatea.db
CHROMA_PATH=./data/chroma

# Optional
PERPLEXICA_URL=http://localhost:3000
SEARXNG_URL=http://localhost:4000
```

---

*"What the user dreams, the engineer builds, and Galatea speaks."*



